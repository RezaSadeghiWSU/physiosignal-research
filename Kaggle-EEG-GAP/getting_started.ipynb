{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "This script will explore [Elena Cuoco's script](https://www.kaggle.com/elenacuoco/grasp-and-lift-eeg-detection/simple-grasp-with-sklearn) in an effort to understand what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# contains important preprocessing tools to read in our data\n",
    "from tools import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# will hold all ids and all predictions\n",
    "all_ids = []\n",
    "all_predictions = []\n",
    "\n",
    "subsample = 100\n",
    "num_subjects = 13\n",
    "num_series = 9\n",
    "human_labels = ['HandStart', 'FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of current dataset: subject= 1 , series= 9  is  (115953, 33)\n",
      "size of current dataset: subject= 1 , series= 10  is  (117128, 33)\n",
      "Training subject_id =  1  label:  HandStart\n",
      "Training subject_id =  1  label:  FirstDigitTouch\n",
      "Training subject_id =  1  label:  BothStartLoadPhase\n",
      "Training subject_id =  1  label:  LiftOff\n",
      "Training subject_id =  1  label:  Replace\n",
      "Training subject_id =  1  label:  BothReleased\n",
      "size of current dataset: subject= 2 , series= 9  is  (147373, 33)\n",
      "size of current dataset: subject= 2 , series= 10  is  (150712, 33)\n",
      "Training subject_id =  2  label:  HandStart\n",
      "Training subject_id =  2  label:  FirstDigitTouch\n",
      "Training subject_id =  2  label:  BothStartLoadPhase\n",
      "Training subject_id =  2  label:  LiftOff\n",
      "Training subject_id =  2  label:  Replace\n",
      "Training subject_id =  2  label:  BothReleased\n",
      "size of current dataset: subject= 3 , series= 9  is  (111945, 33)\n",
      "size of current dataset: subject= 3 , series= 10  is  (113394, 33)\n",
      "Training subject_id =  3  label:  HandStart\n",
      "Training subject_id =  3  label:  FirstDigitTouch\n",
      "Training subject_id =  3  label:  BothStartLoadPhase\n",
      "Training subject_id =  3  label:  LiftOff\n",
      "Training subject_id =  3  label:  Replace\n",
      "Training subject_id =  3  label:  BothReleased\n",
      "size of current dataset: subject= 4 , series= 9  is  (121267, 33)\n",
      "size of current dataset: subject= 4 , series= 10  is  (123527, 33)\n",
      "Training subject_id =  4  label:  HandStart\n",
      "Training subject_id =  4  label:  FirstDigitTouch\n",
      "Training subject_id =  4  label:  BothStartLoadPhase\n",
      "Training subject_id =  4  label:  LiftOff\n",
      "Training subject_id =  4  label:  Replace\n",
      "Training subject_id =  4  label:  BothReleased\n",
      "size of current dataset: subject= 5 , series= 9  is  (131823, 33)\n",
      "size of current dataset: subject= 5 , series= 10  is  (129237, 33)\n",
      "Training subject_id =  5  label:  HandStart\n",
      "Training subject_id =  5  label:  FirstDigitTouch\n",
      "Training subject_id =  5  label:  BothStartLoadPhase\n",
      "Training subject_id =  5  label:  LiftOff\n",
      "Training subject_id =  5  label:  Replace\n",
      "Training subject_id =  5  label:  BothReleased\n",
      "size of current dataset: subject= 6 , series= 9  is  (136853, 33)\n",
      "size of current dataset: subject= 6 , series= 10  is  (142668, 33)\n",
      "Training subject_id =  6  label:  HandStart\n",
      "Training subject_id =  6  label:  FirstDigitTouch\n",
      "Training subject_id =  6  label:  BothStartLoadPhase\n",
      "Training subject_id =  6  label:  LiftOff\n",
      "Training subject_id =  6  label:  Replace\n",
      "Training subject_id =  6  label:  BothReleased\n",
      "size of current dataset: subject= 7 , series= 9  is  (138067, 33)\n",
      "size of current dataset: subject= 7 , series= 10  is  (138957, 33)\n",
      "Training subject_id =  7  label:  HandStart\n",
      "Training subject_id =  7  label:  FirstDigitTouch\n",
      "Training subject_id =  7  label:  BothStartLoadPhase\n",
      "Training subject_id =  7  label:  LiftOff\n",
      "Training subject_id =  7  label:  Replace\n",
      "Training subject_id =  7  label:  BothReleased\n",
      "size of current dataset: subject= 8 , series= 9  is  (123509, 33)\n",
      "size of current dataset: subject= 8 , series= 10  is  (126755, 33)\n",
      "Training subject_id =  8  label:  HandStart\n",
      "Training subject_id =  8  label:  FirstDigitTouch\n",
      "Training subject_id =  8  label:  BothStartLoadPhase\n",
      "Training subject_id =  8  label:  LiftOff\n",
      "Training subject_id =  8  label:  Replace\n",
      "Training subject_id =  8  label:  BothReleased\n",
      "size of current dataset: subject= 9 , series= 9  is  (125715, 33)\n",
      "size of current dataset: subject= 9 , series= 10  is  (126685, 33)\n",
      "Training subject_id =  9  label:  HandStart\n",
      "Training subject_id =  9  label:  FirstDigitTouch\n",
      "Training subject_id =  9  label:  BothStartLoadPhase\n",
      "Training subject_id =  9  label:  LiftOff\n",
      "Training subject_id =  9  label:  Replace\n",
      "Training subject_id =  9  label:  BothReleased\n",
      "size of current dataset: subject= 10 , series= 9  is  (128331, 33)\n",
      "size of current dataset: subject= 10 , series= 10  is  (128906, 33)\n",
      "Training subject_id =  10  label:  HandStart\n",
      "Training subject_id =  10  label:  FirstDigitTouch\n",
      "Training subject_id =  10  label:  BothStartLoadPhase\n",
      "Training subject_id =  10  label:  LiftOff\n",
      "Training subject_id =  10  label:  Replace\n",
      "Training subject_id =  10  label:  BothReleased\n",
      "size of current dataset: subject= 11 , series= 9  is  (136519, 33)\n",
      "size of current dataset: subject= 11 , series= 10  is  (140978, 33)\n",
      "Training subject_id =  11  label:  HandStart\n",
      "Training subject_id =  11  label:  FirstDigitTouch\n",
      "Training subject_id =  11  label:  BothStartLoadPhase\n",
      "Training subject_id =  11  label:  LiftOff\n",
      "Training subject_id =  11  label:  Replace\n",
      "Training subject_id =  11  label:  BothReleased\n",
      "size of current dataset: subject= 12 , series= 9  is  (145669, 33)\n",
      "size of current dataset: subject= 12 , series= 10  is  (142200, 33)\n",
      "Training subject_id =  12  label:  HandStart\n",
      "Training subject_id =  12  label:  FirstDigitTouch\n",
      "Training subject_id =  12  label:  BothStartLoadPhase\n",
      "Training subject_id =  12  label:  LiftOff\n",
      "Training subject_id =  12  label:  Replace\n",
      "Training subject_id =  12  label:  BothReleased\n"
     ]
    }
   ],
   "source": [
    "# we go with 5 samples first\n",
    "\n",
    "for subject_id in range(1,num_subjects):\n",
    "    y_raw = []\n",
    "    raw = []\n",
    "    \n",
    "    # read in training data\n",
    "    for series_id in range(1,num_series):\n",
    "        data,labels = prepare_data_train(subject_id, series_id)\n",
    "        raw.append(data)\n",
    "        y_raw.append(labels)\n",
    "    \n",
    "    \n",
    "    # concatanenate the data sets into one dataframe\n",
    "    X = pd.concat(raw)\n",
    "    y = pd.concat(y_raw)\n",
    "    \n",
    "    X_train = np.asarray(X.astype(float))\n",
    "    y = np.asarray(y.astype(float))\n",
    "    \n",
    "    \n",
    "    test = []\n",
    "    idx = [] # test data ids\n",
    "    \n",
    "    # holds the test data\n",
    "    for series_id in range(9,11):\n",
    "        data = prepare_data_test(subject_id, series_id)\n",
    "        test.append(data)\n",
    "        print 'size of current dataset: subject=',subject_id,', series=',series_id,' is ',data.shape\n",
    "        idx.append(np.array(data['id']))\n",
    "    \n",
    "    X_test = pd.concat(test)\n",
    "    all_ids.append(np.concatenate(idx))\n",
    "    X_test = X_test.drop(['id'], axis=1)\n",
    "    X_test = np.asarray(X_test.astype(float))\n",
    "    \n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    current_prediction = np.empty((X_test.shape[0], 6)) # number of test samples X number of labels\n",
    "    \n",
    "    X_train = data_preprocess_train(X_train)\n",
    "    X_test = data_preprocess_test(X_test)\n",
    "    \n",
    "    # train the classifier for each label\n",
    "    for i in range(6):\n",
    "        print 'Training subject_id = ',subject_id, ' label: ',human_labels[i]\n",
    "        y_train = y[:,i]\n",
    "        lr.fit(X_train[::subsample,:], y_train[::subsample])\n",
    "        current_prediction[:,i] = lr.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    all_predictions.append(current_prediction)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3144171,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(all_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3144171, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(all_predictions).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_file = 'submission1.csv'\n",
    "\n",
    "submission = pd.DataFrame(index=np.concatenate(all_ids), \\\n",
    "                         columns = human_labels, \\\n",
    "                         data = np.concatenate(all_predictions))\n",
    "\n",
    "submission.to_csv(submission_file, index_label='id', float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
