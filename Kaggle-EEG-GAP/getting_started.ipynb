{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "This script will explore [Elena Cuoco's script](https://www.kaggle.com/elenacuoco/grasp-and-lift-eeg-detection/simple-grasp-with-sklearn) in an effort to understand what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# contains important preprocessing tools to read in our data\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in all the data\n",
    "\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "for subject in range(1,5):\n",
    "    for series in range(1,5):\n",
    "        data, labels = prepare_data_train(subject, series)\n",
    "        all_data.append(data)\n",
    "        all_labels.append(labels)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert the data and labels into pandas data frames.\n",
    "\n",
    "X = pd.concat(all_data)\n",
    "Y = pd.concat(all_labels)\n",
    "\n",
    "# transform the training data in the numpy array\n",
    "X_train = np.asarray(X.astype(float))\n",
    "y = np.asarray(Y.astype(float))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have  3311437  recordings and  32  channels each to train on.\n"
     ]
    }
   ],
   "source": [
    "recordings, channels = X_train.shape\n",
    "print 'we have ' , recordings, ' recordings and ', channels, ' channels each to train on.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in the test data\n",
    "\n",
    "\n",
    "for subject in range(1,5):\n",
    "    test_data = [] \n",
    "    idx = [] # holds the ids of the participants\n",
    "    \n",
    "    for series in range(9,11):\n",
    "        data = prepare_data_test(subject, series)\n",
    "        test_data.append(data)\n",
    "        idx.append( np.array( data['id'] ) )\n",
    "\n",
    "    X_test = pd.concat(test_data)\n",
    "    X_test = X_test.drop(['id'], axis=1) # remove ids\n",
    "    X_test = np.asarray( X_test.astype(float) )\n",
    "\n",
    "    ids_tot = np.concatenate(idx) # contains all the ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have  1001299  recordings and  32  channels each to test.\n"
     ]
    }
   ],
   "source": [
    "recordings, channels = X_test.shape\n",
    "print 'we have ' , recordings, ' recordings and ', channels, ' channels each to test.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Subject 1  class  HandStart\n",
      "Train Subject 1  class  FirstDigitTouch\n",
      "Train Subject 1  class  BothStartLoadPhase\n",
      "Train Subject 1  class  LiftOff\n",
      "Train Subject 1  class  Replace\n",
      "Train Subject 1  class  BothReleased\n",
      "Train Subject 2  class  HandStart\n",
      "Train Subject 2  class  FirstDigitTouch\n",
      "Train Subject 2  class  BothStartLoadPhase\n",
      "Train Subject 2  class  LiftOff\n",
      "Train Subject 2  class  Replace\n",
      "Train Subject 2  class  BothReleased\n",
      "Train Subject 3  class  HandStart\n",
      "Train Subject 3  class  FirstDigitTouch\n",
      "Train Subject 3  class  BothStartLoadPhase\n",
      "Train Subject 3  class  LiftOff\n",
      "Train Subject 3  class  Replace\n",
      "Train Subject 3  class  BothReleased\n",
      "Train Subject 4  class  HandStart\n",
      "Train Subject 4  class  FirstDigitTouch\n",
      "Train Subject 4  class  BothStartLoadPhase\n",
      "Train Subject 4  class  LiftOff\n",
      "Train Subject 4  class  Replace\n",
      "Train Subject 4  class  BothReleased\n"
     ]
    }
   ],
   "source": [
    "# classifier training\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# we will use a Logistic Regression Model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# removes the mean and scales the variance to 1\n",
    "X_train = data_preprocess_train(X_train)\n",
    "\n",
    "cols = ['HandStart','FirstDigitTouch',\\\n",
    "        'BothStartLoadPhase','LiftOff',\\\n",
    "        'Replace','BothReleased']\n",
    "\n",
    "subsample = 100\n",
    "\n",
    "predictions = np.empty( ( X_test.shape[0], 6 ) ) # for the number of recordings, we have 6 labels\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "\n",
    "for subject in range(1,5):\n",
    "    for i in range(6): # go through each of the columns \n",
    "        # select the the i'th column for training\n",
    "        y_train = y[:,i] # this holds the label\n",
    "        print 'Train Subject',subject,' class ', cols[i]\n",
    "        lr.fit( X_train[::subsample,:], y_train[::subsample] ) #sample every 100th item.\n",
    "        \n",
    "        predictions[:,i] = lr.predict_proba(X_test)[:,1]\n",
    "        \n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-6d6f8cce86bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'submission1.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_tot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                          \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m                          \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_predictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%.3f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "file_name = 'submission1.csv'\n",
    "\n",
    "submission = pd.DataFrame(index= np.concatenate(ids_tot), \\\n",
    "                         columns = cols, \\\n",
    "                         data = np.concatenate(all_predictions) )\n",
    "submission.to_csv(file_name, index_label='id', float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['subj1_series9_0', 'subj1_series9_1', 'subj1_series9_2', ...,\n",
       "       'subj4_series10_123524', 'subj4_series10_123525',\n",
       "       'subj4_series10_123526'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
